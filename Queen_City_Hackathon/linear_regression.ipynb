{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    " #### Read Train and Test Data\n",
    "training_data = pd.read_csv('/home/rajneesh/Desktop/Queen_City_Hackathon/training.csv', index_col=0)\n",
    "testing_data = pd.read_csv('/home/rajneesh/Desktop/Queen_City_Hackathon/testing.csv', index_col=0)\n",
    "\n",
    "'''\n",
    "### Check for the co relared columns \n",
    "\n",
    "# Create correlation matrix\n",
    "# Create correlation matrix\n",
    "corr_matrix = training_data.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "columns_to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "\n",
    "### Drop all the co-related columns\n",
    "data_nodups_df = training_data.drop(columns=columns_to_drop)\n",
    "'''\n",
    "data_nonull_df = training_data.fillna(training_data.mean())\n",
    "y = data_nonull_df['target']\n",
    "X = data_nonull_df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=300)\n",
    "pca_data = pca.fit_transform(X)\n",
    "#pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scale = StandardScaler()\n",
    "X_train, X_test, y_train, y_test=train_test_split(pca_data, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/py36/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    9.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:   10.6s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   11.5s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   12.3s finished\n",
      "/home/rajneesh/miniconda3/envs/py36/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:00:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'subsample': 0.95, 'reg_lambda': 0.01, 'reg_alpha': 0.01, 'n_estimators': 50, 'min_child_weight': 1.5, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "best score\n",
      "-0.7469941434125701\n"
     ]
    }
   ],
   "source": [
    "parameters_for_testing = {\n",
    "    'colsample_bytree':[0.4,0.6,0.8],\n",
    "    'gamma':[0, 0.03, 0.1, 0.3],\n",
    "    'min_child_weight':[1.5, 4, 6, 8, 10],\n",
    "    'learning_rate':[0.1, 0.3, 0.07, 0.01],\n",
    "    'max_depth':[3, 5, 7],\n",
    "    'n_estimators':[50, 100, 200, 300, 500],\n",
    "    'reg_alpha':[1e-5, 1e-2,  0.75],\n",
    "    'reg_lambda':[1e-5, 1e-2, 0.45],\n",
    "    'subsample':[0.6,0.95]  \n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(learning_rate =0.1, n_estimators=100, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6, scale_pos_weight=1, seed=27)\n",
    "gsearch1 = RandomizedSearchCV(estimator = xgb_model, param_distributions= parameters_for_testing, n_jobs=-1, iid=False, verbose=10, scoring='neg_mean_squared_error')\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print('best params')\n",
    "print (gsearch1.best_params_)\n",
    "print('best score')\n",
    "print (gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params = {\"objective\":\"reg:squarederror\", 'subsample': 0.95, 'reg_lambda': 1e-05, 'reg_alpha': 1e-05, 'n_estimators': 300, 'min_child_weight': 1.5, 'max_depth': 7, 'learning_rate': 0.07, 'gamma': 0.03, 'colsample_bytree': 0.4}\n",
    "# best_params = {'subsample': 0.95, 'reg_lambda': 1e-05, 'reg_alpha': 0.01, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.4}\n",
    "# best_params = {'subsample': 0.95, 'reg_lambda': 1e-05, 'reg_alpha': 1e-05, 'n_estimators': 200, 'min_child_weight': 1.5, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
    "best_params = {'subsample': 0.95, 'reg_lambda': 0.01, 'reg_alpha': 0.01, 'n_estimators': 50, 'min_child_weight': 1.5, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.5,'learning_rate': 0.05, 'max_depth': 5, 'alpha': 10, 'n_estimators': 200}\n",
    "train_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "xg_reg = xgb.train(params=params, dtrain=train_dmatrix, num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_reg.predict(xgb.DMatrix(data=X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06\n",
      "RMSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06\n",
      "RMSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/py36/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/rajneesh/miniconda3/envs/py36/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=xgb.DMatrix(data=pca_data, label=y), num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_nodups_df = testing_data.drop(columns=columns_to_drop)\n",
    "test_nodups_df = testing_data.fillna(training_data.mean())\n",
    "\n",
    "pca_test = pca.transform(test_nodups_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_reg.predict(xgb.DMatrix(data=pca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_to_csv(y_pred):\n",
    "    \"\"\"\n",
    "    Use this function to save your prediction result to a csv file.\n",
    "    The resulting csv file is named as [team_name].csv\n",
    "\n",
    "    :param y_pred: an array or a pandas series that follows the SAME index order as in the testing data\n",
    "    \"\"\"\n",
    "    pd.DataFrame(dict(\n",
    "        target=y_pred\n",
    "    )).to_csv('predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_to_csv(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21879552"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
